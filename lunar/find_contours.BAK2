import cv2
import numpy as np
import concurrent.futures
import gc
import glob
from tqdm.notebook import tqdm

def adjust_clip(image, black=0):
    table = np.concatenate((
        np.zeros(black, dtype="uint8"),
        np.arange(black, 256, dtype="uint8")
    ))
    return cv2.LUT(image, table)

def process_frame(frametext, frame, frame_height, black, minArea, maxArea, video_file, maxy=None):
    clipped = adjust_clip(frame, black=black)
    imgray = cv2.cvtColor(clipped, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(imgray, black, 255, cv2.THRESH_TOZERO)
    contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

    results = []
    for c in contours:
        area = cv2.contourArea(c)
        if minArea <= area <= maxArea:
            M = cv2.moments(c)
            if M["m00"] != 0:
                cX = int(M["m10"] / M["m00"])
                cY = int(M["m01"] / M["m00"])
                cY_flipped = frame_height - cY

                if maxy is not None and cY_flipped > maxy:
                    continue

                mask = np.zeros(imgray.shape, np.uint8)
                cv2.drawContours(mask, [c], 0, 255, -1)
                min_val, max_val, _, _ = cv2.minMaxLoc(imgray, mask=mask)
                mean_val = cv2.mean(frame, mask=mask)

                results.append((frametext, cX, cY_flipped, area, min_val, max_val, mean_val[0], video_file))
    return results

def process_videos(video_files, black=110, minArea=1.5, maxArea=1000.0,
                   brightnessThreshold=200, threads=2, outfile='output.tab', maxy=None,
                   start_time=None, end_time=None):
    cv2.setNumThreads(threads)
    writefile = open('contours_' + outfile, 'w')
    writefile.write("frame\tcX\tcY\tarea\tminI\tmaxI\tmeanI\tvideo\n")

    all_results = []
    cumulative_frame = 0

    for video_file in tqdm(video_files, desc="Processing videos"):
        cap = cv2.VideoCapture(video_file)
        if not cap.isOpened():
            continue

        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        ret, frame = cap.read()
        if not ret:
            cap.release()
            continue

        frame_height = frame.shape[0]
        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
        local_frame_number = 0

        start_frame = int(start_time * fps) if start_time is not None else 0
        end_frame = int(end_time * fps) if end_time is not None else total_frames

        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        cumulative_frame += start_frame

        max_tasks = threads * 2
        with tqdm(total=end_frame - start_frame, desc=f"{video_file}", leave=False) as frame_pbar:
            with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:
                future_to_frame = {}
                while cap.isOpened():
                    current_frame = int(cap.get(cv2.CAP_PROP_POS_FRAMES))
                    if current_frame >= end_frame:
                        break

                    ret, frame = cap.read()
                    if not ret:
                        break

                    average_brightness = cv2.mean(frame)[0]
                    local_frame_number += 1
                    cumulative_frame += 1
                    frame_pbar.update(1)

                    if average_brightness > brightnessThreshold:
                        continue

                    if len(future_to_frame) >= max_tasks:
                        done, _ = concurrent.futures.wait(future_to_frame, return_when=concurrent.futures.FIRST_COMPLETED)
                        for future in done:
                            frame_id = future_to_frame[future]
                            try:
                                results = future.result()
                                all_results.extend(results)
                                for result in results:
                                    writefile.write("\t".join(map(str, result)) + "\n")
                            except Exception as exc:
                                print(f"Frame {frame_id} generated an exception: {exc}")
                            del future_to_frame[future]

                    future = executor.submit(
                        process_frame, cumulative_frame, frame, frame_height,
                        black, minArea, maxArea, video_file, maxy
                    )
                    future_to_frame[future] = cumulative_frame
                    del frame
                    gc.collect()

                for future in concurrent.futures.as_completed(future_to_frame):
                    frame_id = future_to_frame[future]
                    try:
                        results = future.result()
                        all_results.extend(results)
                        for result in results:
                            writefile.write("\t".join(map(str, result)) + "\n")
                    except Exception as exc:
                        print(f"Frame {frame_id} generated an exception: {exc}")

        cap.release()

    writefile.close()
    return all_results

def find_contours_from_videos(video_pattern, black=110, minArea=1.5, maxArea=1000.0,
                              brightnessThreshold=200, threads=2, outfile='output.tab', maxy=None,
                              start_time=None, end_time=None):
    video_files = sorted(glob.glob(video_pattern))
    if not video_files:
        print(f"No videos found matching pattern: {video_pattern}")
        return
    return process_videos(video_files, black, minArea, maxArea, brightnessThreshold,
                          threads, outfile, maxy, start_time, end_time)

# ---------- CLI wrapper ----------
if __name__ == "__main__" and "ipykernel" not in sys.argv[0]:
    import argparse

    def parse_time(timestr):
        parts = timestr.split(":")
        if len(parts) == 1:
            return float(parts[0])
        elif len(parts) == 2:
            minutes = int(parts[0])
            seconds = float(parts[1])
            return minutes * 60 + seconds
        else:
            raise ValueError(f"Invalid time format: {timestr}")

    parser = argparse.ArgumentParser(description="Find and analyze contours in one or more videos.")
    parser.add_argument("-p", "--pattern", required=True,
                        help="Glob pattern for video files, e.g., '*.mp4' or 'data/*.mkv'")
    parser.add_argument("-b", "--black", type=int, default=110,
                        help="Threshold below which pixel values are black (default: 110)")
    parser.add_argument("--minarea", type=float, default=1.5,
                        help="Minimum contour area to keep (default: 1.5)")
    parser.add_argument("--maxarea", type=float, default=1000.0,
                        help="Maximum contour area to keep (default: 1000.0)")
    parser.add_argument("--brightness", type=float, default=200,
                        help="Frame mean brightness above which to skip frame (default: 200)")
    parser.add_argument("--maxy", type=int, default=None,
                        help="Maximum cY value to keep in flipped coordinate system (exclude timestamps etc.)")
    parser.add_argument("-t", "--threads", type=int, default=2,
                        help="Number of threads for parallel processing (default: 2)")
    parser.add_argument("-o", "--outfile", default="output.tab",
                        help="Output filename (default: output.tab)")
    parser.add_argument("-s", "--start", type=str, default=None,
                        help="Start time in seconds or MM:SS (default: None)")
    parser.add_argument("-e", "--end", type=str, default=None,
                        help="End time in seconds or MM:SS (default: None)")

    args = parser.parse_args()
    start_sec = parse_time(args.start) if args.start else None
    end_sec = parse_time(args.end) if args.end else None

    find_contours_from_videos(
        video_pattern=args.pattern,
        black=args.black,
        minArea=args.minarea,
        maxArea=args.maxarea,
        brightnessThreshold=args.brightness,
        threads=args.threads,
        outfile=args.outfile,
        maxy=args.maxy,
        start_time=start_sec,
        end_time=end_sec
    )

